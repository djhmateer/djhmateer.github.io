---
layout: post
title: Task 
description: 
menu: review
categories: Task 
published: true 
comments: false     
sitemap: false
image: /assets/2019-11-13/1.jpg
---
I'm writing a broken link checker, and after fixing my blog and doing lots of crawls it gets frustrating waiting for it to complete. So I need

- To have simultaneous http connections
- Be smart and not DDOS target servers

## Using Task to get multiple connections

[This example comes from MS Docs](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/concepts/async/start-multiple-async-tasks-and-process-them-as-they-complete)

```cs
static async Task Main()
{
    var httpClient = new HttpClient();

    var urlList = SetUpURLList();

    List<Task<(int length, long elapsedMilliseonds)>> downloadTasks = urlList.Select(
        url =>
        {
            return ProcessURL(url, httpClient);
        }).ToList();

    // ***Add a loop to process the tasks one at a time until none remain.
    while (downloadTasks.Count > 0)
    {
        // Identify the first task that completes.
        Task<(int length, long elapsedMilliseconds)> firstFinishedTask = await Task.WhenAny(downloadTasks);

        // ***Remove the selected task from the list so that you don't
        // process it more than once.
        downloadTasks.Remove(firstFinishedTask);

        // Await the completed task.
        var (length, elapsedMilliseconds) = await firstFinishedTask;

        // add a new task - okay this seems to work.
        //downloadTasks.Add(ProcessURL("https://davemateer.com", httpClient));

        Console.WriteLine($"Length of download: {length} in {elapsedMilliseconds}ms");
    }
}

static async Task<(int length, long elapsedMilliseconds)> ProcessURL(string url, HttpClient client)
{
    var sw = Stopwatch.StartNew();
    var httpResponseMessage = await client.GetAsync(url);

    // Retrieve the website contents from the HttpResponseMessage.
    byte[] urlContents = await httpResponseMessage.Content.ReadAsByteArrayAsync();

    return (urlContents.Length, sw.ElapsedMilliseconds);
}

private static List<string> SetUpURLList() =>
    new List<string>
    {
        "https://msdn.microsoft.com",
        "https://msdn.microsoft.com/library/windows/apps/br211380.aspx",
        "https://msdn.microsoft.com/library/hh290136.aspx",
        "https://msdn.microsoft.com/library/dd470362.aspx",
        "https://msdn.microsoft.com/library/aa578028.aspx",
        "https://msdn.microsoft.com/library/ms404677.aspx",
        "https://msdn.microsoft.com/library/ff730837.aspx"
    };
```

I'm not passing a cancellation token (yet), and have commented out a line to add another task while still in the loop which works.

I think this WhenAny solution is appropriate but [if there are too many tasks on the queue](https://devblogs.microsoft.com/pfxteam/processing-tasks-as-they-complete/) then it may not be. I'm going to limit the number of tasks for a different reason below.

## Limiting the tasks

A simlple solution is to limit the number of tasks added to the list:

```cs
// if there are already 2 queries waiting don't put any more on the downloadTasks list
if (downloadTasks.Count > 2)
    await Task.Delay(500);
else
    // add a new task
    downloadTasks.Add(ProcessURL("https://davemateer.com", httpClient));
```

However I want to be smarter:

- Only have 

[Mark Heath blog post on constraining concurrent threads](https://markheath.net/post/constraining-concurrent-threads-csharp) is where I've got a lot of my reserach from

## 1.Concurrent Queue

```cs
 // fill Queue with all urls to download
var q = new ConcurrentQueue<string>(urls);
var tasks = new List<Task>();
for (int n = 0; n < maxThreads; n++)
{
    // start 1 task for each thread that sits in a loop trying to read from the queue
    // exists when no more items left in queue
    tasks.Add(Task.Run(async () =>
    {
        while (q.TryDequeue(out string url))
        {
            var html = await client.GetStringAsync(url);
            Console.WriteLine($"retrieved {html.Length} characters from {url}");
        }
    }));
}
await Task.WhenAll(tasks);
```

This is nice but could lead to threads exiting too early if we're generating more work while still processing.

[Stephen Cleary](https://blog.stephencleary.com/) knows a lot about async programning and he gave some insights in Mark's blog post: (highlighting is mine)

I think it's important to distinguish between synchronous and asynchronous concurrency. 

Synchronous concurrency (parallelism) is using multiple threads, and is an appropriate choice if you have CPU-bound code.

Asynchronous concurrency is a form of concurrency that does not require additional threads, and is an appropriate choice if you have I/O-bound code.

This example (downloading) is I/O-bound, and thus a more appropriate fit for asynchronous concurrency. This is why Parallel / ConcurrentQueue / BlockingCollection solutions end up being awkward - blocking threads, etc. Those types are all firmly in the synchronous concurrency world. It's possible to do solve the problem this way, but it is less efficient.

Downloading is more suited for asynchronous concurrency approaches. This includes SemaphoreSlim with Task.WhenAll (but without the unnecessary Task.Run), and TPL ActionBlock / BufferBlock (works like an asynchronous ConcurrentQueue).

## 2.SemaphoreSlim

> limits the number of threads that can access a resource or pool of resources concurrently

[SO Answer](https://stackoverflow.com/questions/10806951/how-to-limit-the-amount-of-concurrent-async-i-o-operations/10810730#10810730)

```cs
var maxThreads = 4;
var allTasks = new List<Task>();
// there is cancellation in here
var throttler = new SemaphoreSlim(initialCount: maxThreads);
foreach (var url in urls)
{
    // wait until it is okay to queue up/schedule another
    await throttler.WaitAsync();
    // run the lambda in its own parallel flow
    allTasks.Add(
        Task.Run(async () =>
        {
            try
            {
                var html = await client.GetStringAsync(url);
                Console.WriteLine($"retrieved {html.Length} characters from {url}");
            }
            finally
            {
                throttler.Release();
            }
        }));
}
// wont get here until all urls have been up into tasks
await Task.WhenAll(allTasks);
```

- Ends up huge list containing mostly completed Tasks.
- You can generate tasks to be completed at the same time you are executing

## 2.1 Semaphore Slim - Stephen Cleary

[This comes from his comment at the bottom of Mark's article](https://markheath.net/post/constraining-concurrent-threads-csharp)

```cs
var throttler = new SemaphoreSlim(initialCount: maxThreads);
var tasks = urls.Select(async url =>
{
    await throttler.WaitAsync();
    try
    {
        var html = await client.GetStringAsync(url);
        Console.WriteLine($"retrieved {html.Length} characters from {url}");
    }
    finally
    {
        throttler.Release();
    }
});
await Task.WhenAll(tasks);
```

[Use AsyncLock?](https://github.com/StephenCleary/AsyncEx)


## Parallel.ForEach

```cs
// 3. Parallel.ForEach
var options = new ParallelOptions() { MaxDegreeOfParallelism = maxThreads };
Parallel.ForEach(urls, options, url =>
{
    var html = client.GetStringAsync(url).Result;
    Console.WriteLine($"retrieved {html.Length} characters from {url}");
});
```

Nasty gotcha is that becuase `Parallel.ForEach` takes an `Action` not a `Func<T>` it should only be used to call synchronous functions.

Maybe use an [async verion of Parallel.ForEach](https://github.com/Dasync/AsyncEnumerable) which has had 1.32m downloads and [another article here](https://dzone.com/articles/before-c-80-async-streams-come-out) 

```cs
using Dasync.Collections;
await urls.ParallelForEachAsync(
    async url =>
    {
        var html = await client.GetStringAsync(url);
        Console.WriteLine($"retrieved {html.Length} characters from {url}");
    },
    maxDegreeOfParallelism: 4);
```

Can we leverage C#8 IAsyncEnumerable here?

[A Good SO Answer](https://stackoverflow.com/questions/15136542/parallel-foreach-with-asynchronous-lambda)


## BlockingCollection

Producer/Consumer


## Generate a sequential ID thread safe 
