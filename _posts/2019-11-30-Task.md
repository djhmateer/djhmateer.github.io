---
layout: post
title: Task 
description: 
menu: review
categories: Task 
published: false 
comments: false     
sitemap: false
image: /assets/2019-11-13/1.jpg
---
I'm writing a broken link checker, and after fixing my blog and doing lots of crawls it gets frustrating waiting for it to complete. So I need

- To have simultaneous http connections
- Be smart and not DDOS target servers

## Using Task to get multiple connections

[This example comes from MS Docs](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/concepts/async/start-multiple-async-tasks-and-process-them-as-they-complete)

```cs
static async Task Main()
{
    var httpClient = new HttpClient();

    var urlList = SetUpURLList();

    List<Task<(int length, long elapsedMilliseonds)>> downloadTasks = urlList.Select(
        url =>
        {
            return ProcessURL(url, httpClient);
        }).ToList();

    // ***Add a loop to process the tasks one at a time until none remain.
    while (downloadTasks.Count > 0)
    {
        // Identify the first task that completes.
        Task<(int length, long elapsedMilliseconds)> firstFinishedTask = await Task.WhenAny(downloadTasks);

        // ***Remove the selected task from the list so that you don't
        // process it more than once.
        downloadTasks.Remove(firstFinishedTask);

        // Await the completed task.
        var (length, elapsedMilliseconds) = await firstFinishedTask;

        // add a new task 
        //downloadTasks.Add(ProcessURL("https://davemateer.com", httpClient));
        Console.WriteLine($"Length of download: {length} in {elapsedMilliseconds}ms");
    }
}

static async Task<(int length, long elapsedMilliseconds)> ProcessURL(string url, HttpClient client)
{
    var sw = Stopwatch.StartNew();
    var httpResponseMessage = await client.GetAsync(url);

    // Retrieve the website contents from the HttpResponseMessage.
    byte[] urlContents = await httpResponseMessage.Content.ReadAsByteArrayAsync();

    return (urlContents.Length, sw.ElapsedMilliseconds);
}

private static List<string> SetUpURLList() =>
    new List<string>
    {
        "https://msdn.microsoft.com",
        "https://msdn.microsoft.com/library/windows/apps/br211380.aspx",
        "https://msdn.microsoft.com/library/hh290136.aspx",
        "https://msdn.microsoft.com/library/dd470362.aspx",
        "https://msdn.microsoft.com/library/aa578028.aspx",
        "https://msdn.microsoft.com/library/ms404677.aspx",
        "https://msdn.microsoft.com/library/ff730837.aspx"
    };
```

[Is async await concurrent](https://stackoverflow.com/a/7663734/26086) is a good question ie should I be worried about thread safety writing back to the downloadTasks?

I'm not passing a cancellation token (yet), and have commented out a line to add another task while still in the loop which works.

I think this WhenAny solution is appropriate but [if there are too many tasks on the queue](https://devblogs.microsoft.com/pfxteam/processing-tasks-as-they-complete/) then it may not be. I'm going to limit the number of tasks for a different reason below.

## Limiting the tasks

A simple solution is to limit the number of tasks added to the list:

```cs
// if there are already 2 queries waiting don't put any more on the downloadTasks list
if (downloadTasks.Count > 2)
    await Task.Delay(500);
else
    // add a new task
    downloadTasks.Add(ProcessURL("https://davemateer.com", httpClient));
```

## 1.Concurrent Queue

[Mark Heath blog post on constraining concurrent threads](https://markheath.net/post/constraining-concurrent-threads-csharp) is where I've got a lot of my research from

[MS Docs on System.Collections.Concurrent](https://docs.microsoft.com/en-us/dotnet/api/system.collections.concurrent?view=netframework-4.8) 

```cs
 // fill Queue with all urls to download
var q = new ConcurrentQueue<string>(urls);
var tasks = new List<Task>();
for (int n = 0; n < maxThreads; n++)
{
    // start 1 task for each thread that sits in a loop trying to read from the queue
    // exists when no more items left in queue
    tasks.Add(Task.Run(async () =>
    {
        while (q.TryDequeue(out string url))
        {
            var html = await client.GetStringAsync(url);
            Console.WriteLine($"retrieved {html.Length} characters from {url}");
        }
    }));
}
await Task.WhenAll(tasks);
```

This is nice but could lead to threads exiting too early if we're generating more work while still processing.

## Synchronous vs Asynchronous concurrency

[Stephen Cleary](https://blog.stephencleary.com/) knows a lot about async programning and he gave some insights in Mark's blog post: (highlighting is mine)

"I think it's important to distinguish between synchronous and asynchronous concurrency. 

Synchronous concurrency (parallelism) is using multiple threads, and is an appropriate choice if you have CPU-bound code.

Asynchronous concurrency is a form of concurrency that does not require additional threads, and is an appropriate choice if you have I/O-bound code.

This example (downloading) is I/O-bound, and thus a more appropriate fit for asynchronous concurrency. This is why Parallel / ConcurrentQueue / BlockingCollection solutions end up being awkward - blocking threads, etc. Those types are all firmly in the synchronous concurrency world. It's possible to do solve the problem this way, but it is less efficient.

Downloading is more suited for asynchronous concurrency approaches. This includes SemaphoreSlim with Task.WhenAll (but without the unnecessary Task.Run), and TPL ActionBlock / BufferBlock (works like an asynchronous ConcurrentQueue)."

## 1.1 Concurrent Queue with Concurrent Dictionary

I want to be able to:

- Limit total httpConnections to 20
- Limit httpConnections to a baseUrl to 2

So the code below is using synchronous concurrency (parallelism) ie multiple threads. As Stephen said this could be awkward as I may end up blocking threads, but.. it works.

```cs
static async Task Main()
{
    var urls2 = new List<string>
    {
        "https://github.com/naudio/NAudio",
        "https://twitter.com/mark_heath",
        "https://github.com/markheath/azure-functions-links",
        "https://pluralsight.com/authors/mark-heath",
        "https://github.com/markheath/advent-of-code-js",
        "http://stackoverflow.com/users/7532/mark-heath",
        "https://mvp.microsoft.com/en-us/mvp/Mark%20%20Heath-5002551",
        "https://github.com/markheath/func-todo-backend",
        "https://github.com/markheath/typescript-tetris",
    };

    var urls1 = Enumerable.Range(1, 20).Select(x => "https://davemateer.com");
    var urls = urls1.Concat(urls2);

    var httpClient = new HttpClient();

    var maxThreads = 10;
    var maxConnectionsToBaseUrl = 2;

    // fill queue with initial urls
    var queueOfUrlsToRequest = new ConcurrentQueue<string>(urls);

    // baseurl, count
    var dictionaryOfBaseUrlsCurrentlyRequesting = new ConcurrentDictionary<string, int>();

    var tasks = new List<Task>();
    for (int n = 0; n < maxThreads; n++)
    {
        //  stagger the start of each thread so dictionary has a chance to increment
        await Task.Delay(10 * n);
        // start a task for each thread that sits in a loop trying to read urls from the queue
        tasks.Add(Task.Run(async () =>
        {
            while (queueOfUrlsToRequest.TryDequeue(out var url))
            {
                // lookup dictionary to see if we have 2 requests already going to this baseurl
                dictionaryOfBaseUrlsCurrentlyRequesting.TryGetValue(url, out var numberOfConnectionsToBaseUrl);

                if (numberOfConnectionsToBaseUrl < maxConnectionsToBaseUrl)
                {
                    dictionaryOfBaseUrlsCurrentlyRequesting.TryGetValue(url, out numberOfConnectionsToBaseUrl);
                    Console.WriteLine($"Task found work {url} {numberOfConnectionsToBaseUrl}");
                    // increment value so other tasks know this httpRequest is happening
                    dictionaryOfBaseUrlsCurrentlyRequesting.AddOrUpdate(url, 1, (s, oldValue) => oldValue + 1);

                    dictionaryOfBaseUrlsCurrentlyRequesting.TryGetValue(url, out numberOfConnectionsToBaseUrl);
                    Console.WriteLine($"incremented {url} {numberOfConnectionsToBaseUrl}");
                    var html = await httpClient.GetStringAsync(url);
                    // decrement value in dictionary 
                    dictionaryOfBaseUrlsCurrentlyRequesting.AddOrUpdate(url, 1, (url, oldValue) => oldValue - 1);

                    Console.WriteLine($"retrieved {html.Length} characters from {url}");
                }
                else
                {
                    Console.WriteLine("Task looking for work, but maxed out allowable connections to baseurl, so have put item back on queue");
                    DisplayDictionary();
                    // put url back on queue as too many connections to baseUrl
                    queueOfUrlsToRequest.Enqueue(url);
                    await Task.Delay(100);
                }
            }
        }));
    }

    await Task.WhenAll(tasks);

    DisplayDictionary();

    void DisplayDictionary()
    {
        Console.WriteLine("\nDictionary of baseurl : count of current requests");
        foreach (var (key, value) in dictionaryOfBaseUrlsCurrentlyRequesting) Console.WriteLine($"{key} : {value}");
        Console.WriteLine(queueOfUrlsToRequest.Count);
    }
}

```

So this behaves as you would expect.

Is it thread safe? I think so as the [upsert - AddOrUpdate to the dictionary](https://stackoverflow.com/a/7132913/26086) is thread safe.

[Adding urls to the queue](https://stackoverflow.com/questions/43117502/thread-safety-in-concurrent-queue-c-sharp) should be thread safe.

As always there are definately better ways of doing this, however I need to release this product!

## 2.SemaphoreSlim

> limits the number of threads that can access a resource or pool of resources concurrently

[SO Answer](https://stackoverflow.com/questions/10806951/how-to-limit-the-amount-of-concurrent-async-i-o-operations/10810730#10810730)

```cs
var maxThreads = 4;
var allTasks = new List<Task>();
// there is cancellation in here
var throttler = new SemaphoreSlim(initialCount: maxThreads);
foreach (var url in urls)
{
    // wait until it is okay to queue up/schedule another
    await throttler.WaitAsync();
    // run the lambda in its own parallel flow
    allTasks.Add(
        Task.Run(async () =>
        {
            try
            {
                var html = await client.GetStringAsync(url);
                Console.WriteLine($"retrieved {html.Length} characters from {url}");
            }
            finally
            {
                throttler.Release();
            }
        }));
}
// wont get here until all urls have been up into tasks
await Task.WhenAll(allTasks);
```

- Ends up huge list containing mostly completed Tasks.
- You can generate tasks to be completed at the same time you are executing

## 2.1 Semaphore Slim - Stephen Cleary

[This comes from his comment at the bottom of Mark's article](https://markheath.net/post/constraining-concurrent-threads-csharp)

```cs
var throttler = new SemaphoreSlim(initialCount: maxThreads);
var tasks = urls.Select(async url =>
{
    await throttler.WaitAsync();
    try
    {
        var html = await client.GetStringAsync(url);
        Console.WriteLine($"retrieved {html.Length} characters from {url}");
    }
    finally
    {
        throttler.Release();
    }
});
await Task.WhenAll(tasks);
```

[Use AsyncLock?](https://github.com/StephenCleary/AsyncEx)


## Parallel.ForEach

```cs
// 3. Parallel.ForEach
var options = new ParallelOptions() { MaxDegreeOfParallelism = maxThreads };
Parallel.ForEach(urls, options, url =>
{
    var html = client.GetStringAsync(url).Result;
    Console.WriteLine($"retrieved {html.Length} characters from {url}");
});
```

Nasty gotcha is that becuase `Parallel.ForEach` takes an `Action` not a `Func<T>` it should only be used to call synchronous functions.

Maybe use an [async verion of Parallel.ForEach](https://github.com/Dasync/AsyncEnumerable) which has had 1.32m downloads and [another article here](https://dzone.com/articles/before-c-80-async-streams-come-out) 

```cs
using Dasync.Collections;
await urls.ParallelForEachAsync(
    async url =>
    {
        var html = await client.GetStringAsync(url);
        Console.WriteLine($"retrieved {html.Length} characters from {url}");
    },
    maxDegreeOfParallelism: 4);
```

Can we leverage C#8 IAsyncEnumerable here?

[A Good SO Answer](https://stackoverflow.com/questions/15136542/parallel-foreach-with-asynchronous-lambda)


## BlockingCollection

Producer/Consumer


## Generate a sequential ID thread safe 
